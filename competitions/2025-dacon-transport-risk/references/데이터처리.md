1) 데이터 무결성·누수 점검

데이터스플릿을 먼저 고정하고 그 안에서만 전처리를 하도록 파이프라인화한다. 시간/그룹 의존성이 있으면 TimeSeriesSplit 또는 GroupKFold를 쓴다. 타깃과 유의미하게 직접 연결된 파생 변수(미래 정보, 타깃에서 파생된 통계치 등)를 제거한다. 누수 의심 피처는 permutation importance로 스플릿 밖 성능 대비 스플릿 안 성능이 과도하게 높다면 제외한다.

2) 타깃 분포 처리

y가 치우치면 log1p, Yeo–Johnson 같은 변환을 검토한다. TransformedTargetRegressor로 모델을 감싸면 학습·예측 시 자동 변환/역변환을 해준다. 라벨 확산이 큰 경우 quantile loss(예: LGBM의 quantile)나 Huber 같은 로버스트 손실로 바꾸는 것도 방법이다.

3) 스케일링·이상치 완화

선형계열/거리기반 모델을 쓸 가능성이 있으면 RobustScaler로 스케일링한다. 극단치가 많은 컬럼은 윈저라이즈(상·하위 q% 클리핑)나 IQR 기반 캡핑을 검토한다. 이상치 자체가 의미 있는 이벤트라면 별도 플래그 피처를 추가해 보수적으로 처리한다.

4) 결측값 전략 고정

SimpleImputer/IterativeImputer 등으로 수치·범주를 분리 처리하고, 결측 플래그를 추가해 결측 자체의 정보를 보존한다. 반드시 파이프라인 내부에서 fit한다.

5) 다중공선성·차원 축소

높은 상관 컬럼은 한쪽 제거 또는 PCA/FA로 압축한다. 선형 모델을 쓸 땐 VIF를 보거나 L1/L2 정규화로 안정화한다. 트리계열만 쓸 거라면 굳이 강제 축소는 필요 없지만, 매우 고차원이라면 PCA로 노이즈를 줄여 학습 속도를 높일 수 있다.

6) 피처 선택의 마지막 한 끗

훈련 folds 내부에서만 수행되는 선택 기법으로 고정한다. mutual_info_regression, 모델 기반 중요도(ElasticNet, Gradient Boosting), permutation importance를 교차검증 안쪽에서 사용하고, 선택 결과의 일관성(각 fold에서의 선택 빈도)을 본다.

7) 평가 프로토콜 설계

메트릭을 문제 성격에 맞게 명확히 정한다. 스케일 민감도 낮추려면 MAPE/SMAPE, 큰 오차에 패널티를 주려면 RMSE, 상대 비교면 R² 등. 회귀에서도 층화가 필요하면 y를 구간화해 StratifiedKFold처럼 나눈다.

8) 교차검증·튜닝 자동화

RepeatedKFold 또는 시계열이면 expanding-window CV를 쓴다. 하이퍼튜닝은 Optuna/RandomizedSearchCV로 탐색 공간을 넓게 잡고, 스코어는 위에서 정한 메트릭으로 일관되게 평가한다. 조기종료가 있는 모델이면 early stopping을 사용하되 검증 세트 누수를 막기 위해 fit에서 eval_set을 분리한다.

9) 해석·검증

SHAP/Permutation importance로 전역·국소 설명을 확인한다. 잔차 진단으로 비선형성/이분산성을 본다. 피처별 PDP/ICE로 모델이 비합리한 방향으로 반응하지 않는지 체크한다. 필요 시 monotonic constraint를 지원하는 모델(LightGBM/XGBoost)로 제약을 걸어 일관성을 확보한다.

10) 배포 관점 고정

전처리·모델·후처리를 하나의 sklearn Pipeline로 묶는다. 입력 스키마, 결측/카테고리 unknown 처리, 버전 고정을 한다. 예측 후 역변환(log1p 등)과 클리핑 규칙을 같이 묶어둔다.